{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reinforcement Learning fundamentals**\n",
    "\n",
    "Class goals:\n",
    "- acquire the fundamental building blocks of RL:\n",
    "    - plain word notions\n",
    "    - MDPs, policies, optimality equations, etc.\n",
    "    - common notations\n",
    "    - key algorithms\n",
    "    - common misconceptions\n",
    "- key challenges in RL and their connection to RLVS lectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL in plain words (15 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keywords:\n",
    "- system to control / environment\n",
    "- control policy\n",
    "- expected value\n",
    "- optimality\n",
    "\n",
    "The patient example.\n",
    "\n",
    "Misconceptions:\n",
    "- the agent is not separated from the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice: plot trajectories for the systems below (HIV, bicycle, breakout, mountain car)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL within Machine Learning (5 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table comparing SL, UL, RL\n",
    "\n",
    "Delayed rewards, credit assignement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling sequential decision problems: Markov Decision Processes (30 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MDP definition\n",
    "- Policies\n",
    "- Criteria and value functions\n",
    "- Optimality and optimal policies\n",
    "- Stationary distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's take a short break**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterizing value functions: the Bellman equations (20 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q functions\n",
    "- evaluation equation\n",
    "- optimality equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming for MDPs (30 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- value iteration\n",
    "- policy iteration and modified policy iteration\n",
    "- approximate dynamic programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's take a short break**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning optimal value functions (30 minutes)\n",
    "\n",
    "- AVI -> QL\n",
    "- API -> SARSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct policy optimization (15 minutes)\n",
    "\n",
    "- max V -> DPS and PG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three fundamental challenges in RL (10 minutes)\n",
    "\n",
    "Function approximation, exploration, optimality.\n",
    "\n",
    "These challenges are intrinsic to RL.  \n",
    "But there are countless others, that depend on the context, e.g.:\n",
    "- Hierarchical RL\n",
    "- Multi agent RL\n",
    "- Partially observable MDPs\n",
    "- Robust RL\n",
    "- Offline RL\n",
    "- Transfer in RL\n",
    "\n",
    "Connection to RLVS classes (map of RLVS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "186px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
